{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Clustering for Semi-Supervised Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How semi-supervised learning works\n",
    "\n",
    "Imagine, you have collected a large set of unlabeled data that you want to train a model on. Manual labeling of all this information will probably cost you a fortune, besides taking months to complete the annotations. That’s when the semi-supervised machine learning method comes to the rescue.\n",
    "\n",
    " Instead of adding tags to the entire dataset, you go through and hand-label just a small part of the data and use it to train a model, which then is applied to the ocean of unlabeled data.\n",
    "\n",
    " Self-training\n",
    "One of the simplest examples of semi-supervised learning, in general, is self-training.\n",
    "\n",
    "\n",
    "Self-training is the procedure in which you can take any supervised method for classification or regression and modify it to work in a semi-supervised manner, taking advantage of labeled and unlabeled data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co-training\n",
    "\n",
    "Derived from the self-training approach and being its improved version, co-training is another semi-supervised learning technique used when only a small portion of labeled data is available. Unlike the typical process, co-training trains two individual classifiers based on two views of data.\n",
    "\n",
    "The views are basically different sets of features that provide additional information about each instance, meaning they are independent given the class. Also, each view is sufficient — the class of sample data can be accurately predicted from each set of features alone.\n",
    "\n",
    "The original co-training research paper claims that the approach can be successfully used, for example, for web content classification tasks. The description of each web page can be divided into two views: one with words occurring on that page and the other with anchor words in the link leading to it.\n",
    "\n",
    "https://www.altexsoft.com/blog/semi-supervised-learning/\n",
    "\n",
    "https://content.altexsoft.com/media/2022/03/semi-supervised-co-training-method.png.webp\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "\n",
    "\n",
    "number=0\n",
    "print('shape :',x_test.shape)\n",
    "plt.imshow(x_train[number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8066666666666666"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_labeled = 50\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train[:n_labeled], y_train[:n_labeled])\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is just 84.7%: it should come as no surprise that this is much lower than\n",
    "earlier, when we trained the model on the full training set. Let’s see how we can do\n",
    "better. First, let’s cluster the training set into 50 clusters, then for each cluster let’s find\n",
    "the image closest to the centroid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 9, 8, 2, 3, 6, 0, 5, 0, 5, 8, 1, 0, 9, 3, 3, 0, 3, 7, 0, 5,\n",
       "       0, 9, 1, 4, 7, 8, 8, 6, 8, 2, 4, 4, 5, 4, 1, 8, 5, 2, 5, 1, 0, 3,\n",
       "       4, 0, 7, 4, 4, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:n_labeled]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit transpose give distance of datapoint in clustter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 0, 3, 6, 4, 2, 5, 7, 7, 4, 5, 1, 0, 7, 3, 6, 9, 9, 8, 1, 1,\n",
       "       2, 7, 4, 2, 2, 8, 9, 9, 6, 9, 0, 8, 5, 7, 4, 3, 1, 7, 6, 7, 5, 1,\n",
       "       4, 7, 3, 4, 4, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 50\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "X_digits_dist = kmeans.fit_transform(X_train)\n",
    "representative_digit_idx = np.argmin(X_digits_dist, axis=0)\n",
    "X_representative_digits = X_train[representative_digit_idx]\n",
    "\n",
    "y_representative_digits = np.array([4,8,0,6,8,3,7,7,9,2,5,5,8,5,2,1,2,9,6,1,1,6,9,0,8,3,0,7,4,1,6,5,2,4,1,8,6,3,9,2,4,2,9,4,7,6,2,3,1,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  54  765   66  291  562  848 1337    8  355  472 1300 1321  838  174\n",
      "  800 1037 1141  885  954  725 1215  204  438  602 1081 1127  209 1232\n",
      "  745  193 1270  336  915  369 1137 1252 1190  532  810 1070 1269  748\n",
      "  365 1310  734  717  360  429 1338  951]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  2., 11., 16., 16., 16.,  4.,  0.,  0.,  5., 11.,  8.,\n",
       "         8., 16.,  1.,  0.,  0.,  0.,  0.,  0., 14.,  6.,  0.,  0.,  0.,\n",
       "         2., 10., 13., 16., 13.,  0.,  0.,  0., 12., 16., 16.,  9.,  2.,\n",
       "         0.,  0.,  0.,  2.,  5., 14.,  0.,  0.,  0.,  0.,  0.,  0., 11.,\n",
       "         9.,  0.,  0.,  0.,  0.,  0.,  0., 16.,  6.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(representative_digit_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1111111111111111"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_representative_digits, y_representative_digits)\n",
    "log_reg.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd68b8f677b2174759d58ebb78708f365337139cf5b4c53cee403bb05ecba74d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
